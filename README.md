# ðŸ—ï¸Overview

![flow_chart.png]([attachment:c0182734-5019-4e01-9679-103c35a082b2:flow_chart.png](https://github.com/haopinn/arxiv-data-pipeline/blob/main/flow_chart.png?raw=true))


# ðŸ“‚ Directory Structure
```docker
.
â”‚
â”œâ”€â”€ .env                       # Environment variables
â”œâ”€â”€ Dockerfile                 # Kafka consumer Docker image definition
â”œâ”€â”€ Dockerfile.airflow         # Airflow container Docker image definition
â”‚
â”œâ”€â”€ docker-compose.yaml        # Docker Compose services setup
â”‚
â”œâ”€â”€ poetry.lock                # Poetry dependency lock file
â”œâ”€â”€ poetry.toml                # Poetry tool settings
â”œâ”€â”€ pyproject.toml             # Project and dependency definition
â”‚
â”œâ”€â”€ README.md                  # Project documentation (this file)
â”‚
â”œâ”€â”€ docker/                    # Container-specific setup and configs
â”‚   â””â”€â”€ airflow/               # Airflow DAGs and runtime logic
â”‚       â””â”€â”€ dags/              # DAG definition scripts
â”‚   â””â”€â”€ prometheus/            # Configuration of Prometheus
â”‚
â”œâ”€â”€ src/                       # Core Python source code
â”‚   â”œâ”€â”€ client/                # Connectors for PostgreSQL, Kafka, Iceberg, etc.
â”‚   â”œâ”€â”€ data_fetcher/          # Fetch raw data from arXiv and Crossref APIs
â”‚   â”œâ”€â”€ data_processor/        # Transform and clean raw fetched data
â”‚   â”œâ”€â”€ data_validator/        # Validate data using Great Expectations
â”‚   â”œâ”€â”€ kafka_message/         # Kafka message generators and transformers
â”‚   â”œâ”€â”€ monitoring/            # Prometheus metric collection and tracking
â”‚   â”œâ”€â”€ pipeline/              # High-level pipeline orchestration logic
â”‚   â”œâ”€â”€ schema/                # Pydantic and internal data schemas
â”‚   â”œâ”€â”€ script/                # Initialization/demo scripts (e.g., create tables)
â”‚   â”œâ”€â”€ storage/               # Save dataframes to Iceberg or other storage
â”‚   â””â”€â”€ utils/                 # Utility functions and configuration loaders
```


# âš™ï¸ Project Setup

Use **Docker Compose** to start all services:

```docker
docker compose --env-file .env.dev up -d
```

> âš ï¸ Warning â€“ Demo Environment Only âš ï¸
> 
> 
> This project is intended for **demonstration purposes only**. It is **not recommended** to build or run the current Docker setup in a production or sensitive environment due to the following concerns:
> 
> 1. **Image size is not optimized**: The container images are large and may consume unnecessary disk space or memory.
> 2. **Potential security risk**: To enable cross-container operations (especially for Airflow), the Docker socket (`/var/run/docker.sock`) is mounted as a volume. This may pose **security risks** by exposing Docker daemon access from inside the container.


# ðŸ§± Docker Services Overview

| Service Name | Image / Component | Purpose / Role |
| --- | --- | --- |
| `airflow-webserver` | `airflow-custom` | Web UI for managing DAGs and Airflow tasks |
| `airflow-scheduler` | `airflow-custom` | Triggers tasks based on schedule |
| `airflow-worker` | `airflow-custom` | Executes Airflow tasks |
| `airflow-triggerer` | `airflow-custom` | Handles trigger-based tasks (e.g., sensors) |
| `postgres` | `postgres:13` | Metadata DB for Airflow |
| `redis` | `redis:7.2-bookworm` | Celery broker for Airflow task queues |
| `kafka` | `confluentinc/cp-kafka:7.8.0` | Message broker for event-driven architecture |
| `zookeeper` | `confluentinc/cp-zookeeper:7.8.0` | Required for Kafka cluster coordination |
| `kafka-schema-registry` | `confluentinc/cp-schema-registry:7.8.0` | Manages Avro/Protobuf/JSON schemas for Kafka messages |
| `kafka-connect` | `confluentinc/cp-kafka-connect:7.8.0` | Kafka Connect service for ingest/export pipelines (e.g., MinIO, Iceberg) |
| `arxiv-data-pipeline-kafka-consumer` | `arxiv-data-pipeline-kafka-consumer` | Custom Python consumer for processing arXiv metadata |
| `minio` | `minio/minio` | S3-compatible object storage for storing intermediate and final data |
| `minio-client` | `minio/mc` | Utility container to initialize/configure MinIO |
| `iceberg-rest` | `apache/iceberg-rest-fixture` | REST Catalog for Apache Iceberg metadata operations |
| `spark-iceberg` | `tabulario/spark-iceberg` | Spark engine for querying and writing to Iceberg tables |
| `prometheus` | `prom/prometheus` | Metrics collection for monitoring pipeline health |
| `statsd-exporter` | `prom/statsd-exporter` | Translates statsd metrics into Prometheus format |
| `grafana` | `grafana/grafana:latest` | Visualization layer for monitoring metrics |
